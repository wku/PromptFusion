# Документация по промпт-инструментам для CodebaseGPT

## Обзор
Это решение заменяет механизм инструментов API OpenAI на промпт-инжиниринг для работы с проектом через LLM. Основная проблема, которую оно решает — несовместимость OpenRouter API с механизмом функций OpenAI, что проявляется в отсутствии поля `usage` в ответе и приводит к ошибкам в работе приложения.

## Файлы и их назначение

### 1. `prompt_tools.py`
Основной модуль, реализующий инструменты через промпт-инжиниринг.

### 2. `improved_chat_session.py`
Альтернативная реализация сессии чата, использующая промпт-инструменты.

## Архитектура решения

### Класс `PromptTools`
Ключевой класс, который инкапсулирует всю логику работы с инструментами через промпты.

#### Основные методы:
- `get_tools_system_prompt()` — формирует инструкции для LLM по использованию функций
- `enhance_system_prompt(original_prompt)` — добавляет инструкции к системному промпту
- `process_user_message(message)` — обрабатывает сообщения пользователя с вызовами функций
- `process_bot_response(response)` — обрабатывает ответы LLM, заменяя вызовы функций результатами

#### Функциональные методы:
- `get_file_func(path)` — загружает содержимое файла
- `find_files_semantic_func(query, page)` — ищет файлы семантически
- `find_in_files_func(query, is_case_sensitive, page)` — ищет текст в файлах
- `update_file_func(path, content)` — обновляет или создает файл

### Функция `start_chat_session`
Основная функция из `improved_chat_session.py`, которая запускает интерактивный чат с LLM.

## Принцип работы

1. **Системный промпт:** 
   - Стандартный системный промпт дополняется инструкциями по использованию функций
   - Формат вызова функций: `[FUNCTION: имя_функции(параметр="значение")]`

2. **Обработка сообщений пользователя:**
   - Если пользователь напрямую вызывает функцию (например, для тестирования), 
     она выполняется и результат выводится

3. **Обработка ответов LLM:**
   - Ответы LLM обрабатываются и вызовы функций заменяются их результатами
   - LLM может вызывать функции, которые выполняются на стороне клиента
   - Результаты оформляются в виде: `[RESULT: имя_функции]...результат...[/RESULT]`

4. **Итеративная обработка:**
   - Ответ обрабатывается в цикле, пока все вызовы функций не будут заменены результатами

## Примеры форматов

### Вызов функции:
```
[FUNCTION: get_file(path="./main.py")]
```

### Результат выполнения:
```
[RESULT: get_file]
Файл: ./main.py
Содержимое:
```python
def main():
    print("Hello world")
```
[/RESULT]
```

## Интеграция в проект

### 1. Добавление файлов:
- Скопируйте `prompt_tools.py` и `improved_chat_session.py` в корневую директорию проекта

### 2. Изменение импортов в app.py:
```python
# Заменить
from core import initialize_project, analyze_project_files, start_chat_session

# На
from core import initialize_project, analyze_project_files
from improved_chat_session import start_chat_session
```

### 3. Установка зависимостей:
```
pip install sentence-transformers scikit-learn numpy
```

## Преимущества подхода

1. **Надежность:** Не зависит от поддержки функций API на стороне провайдера
2. **Прозрачность:** Вызовы функций и их результаты видны в истории чата
3. **Расширяемость:** Легко добавлять новые функции без изменения API
4. **Унифицированность:** Работает с любыми LLM, которые следуют инструкциям

## Ограничения

1. Зависит от способности LLM корректно следовать формату
2. Увеличивает размер промптов за счет включения результатов функций
3. Не поддерживает параллельное выполнение функций

## Диагностика проблем

Если LLM неправильно форматирует вызовы функций:
1. Убедитесь, что системный промпт содержит четкие инструкции
2. Рассмотрите добавление примеров использования функций
3. Используйте более строгую температуру (0-0.2) для более предсказуемых результатов

Для отладки можно добавить дополнительные выводы в методы `process_user_message` и `process_bot_response` класса `PromptTools`.

## Заключение

Данное решение обеспечивает стабильную работу с OpenRouter API, обходя проблемы совместимости с механизмом функций OpenAI. 
Такой подход делает взаимодействие с кодовой базой более надежным и универсальным, позволяя использовать различные API провайдеров 
без изменения основной функциональности.



