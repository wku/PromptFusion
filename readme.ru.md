# PromptFusion: Интеллектуальный анализ кодовых баз

## Основное назначение

PromptFusion - специализированный инструмент для глубокого исследования и быстрого понимания крупных кодовых баз с использованием возможностей больших языковых моделей (LLM). Основная цель проекта - значительно ускорить процесс анализа больших программных проектов, состоящих из множества файлов, помогая разработчикам быстро находить ответы на вопросы или выявлять проблемы в незнакомом коде.

Инструмент особенно полезен в следующих сценариях:
- Первичное знакомство с новой кодовой базой
- Поиск конкретных реализаций функциональности в большом проекте
- Изучение взаимосвязей между компонентами сложной системы
- Выявление потенциальных проблем или узких мест в архитектуре
- Получение детального понимания работы кода без необходимости ручного анализа каждого файла

## О проекте

PromptFusion представляет собой инструмент для взаимодействия с кодовыми базами с использованием больших языковых моделей (LLM). Проект позволяет анализировать, ориентироваться и получать консультации по кодовым базам с использованием генеративных языковых моделей.

### Ключевые возможности

- Анализ структуры проекта и описание файлов
- Семантический поиск по всей кодовой базе
- Интерактивный ИИ-чат для обсуждения кода
- Поддержка множества языков программирования
- Оптимизация затрат на API

## Установка

1. Клонировать репозиторий
```bash
git clone https://github.com/wku/PromptFusion
cd PromptFusion
```

2. Установить зависимости
```bash
pip install -r requirements.txt
```

3. Создать файл `.env` в корне проекта
```
OPENROUTER_API_KEY=ваш_api_ключ
```

## Использование

### Запуск

```bash
python app.py
```

При первом запуске вам будет предложено указать путь к проекту для анализа. Программа создаст индекс файлов проекта и их описания с использованием LLM.

### Основные команды чата

- Задавайте вопросы о структуре и функциональности проекта
- `/clear` - очистить историю сообщений
- `/exit` - выйти из чата

### Примеры вопросов

- "Объясни основную структуру проекта"
- "Как реализована функция X в файле Y?"
- "Найди все места, где используется класс Z"
- "Расскажи о взаимодействии между модулями A и B"
- "Какие проблемы есть в архитектуре проекта?"
- "Как реализована обработка ошибок в модуле аутентификации?"

## Архитектура проекта

### Ключевые модули

- **analyzers.py** - Анализаторы структуры кода для различных языков
- **app.py** - Точка входа в приложение
- **config.py** - Управление конфигурацией
- **core.py** - Основная логика приложения
- **improved_chat_session.py** - Реализация чата с инструментами промптов
- **models.py** - Модели данных
- **prompt_tools.py** - Инструменты промптов для работы с LLM

### Поддерживаемые языки программирования

- Python
- JavaScript/TypeScript
- Java
- C/C++
- Go
- Rust
- Solidity

## Инструменты промптов

Проект использует инновационный подход к взаимодействию с LLM через инженерию промптов вместо стандартных функций API. Это обеспечивает совместимость с различными провайдерами LLM.

### Как работают инструменты промптов

1. Инструкции по использованию функций добавляются в системный промпт
2. LLM может вызывать функции в формате `[FUNCTION: function_name(parameter="value")]`
3. Вызовы функций обрабатываются и заменяются результатами в формате `[RESULT: function_name]...result...[/RESULT]`

### Доступные функции

- `get_file(path)` - Загружает содержимое файла
- `find_files_semantic(query, page)` - Ищет файлы с использованием семантического поиска
- `find_in_files(query, is_case_sensitive, page)` - Ищет текст в файлах
- `update_file(path, content)` - Обновляет или создает файл

## Режимы анализа

Проект поддерживает различные режимы описания файлов:

- **MODE_DESC** - Полные описания (стандартный режим)
- **MODE_DESC_NO** - Без описаний
- **MODE_DESC_2** - Краткие описания

## Оптимизация затрат

Система автоматически отслеживает:
- Количество токенов в запросах/ответах
- Стоимость API-запросов
- Размеры файлов

Она предупреждает о больших файлах и проектах, которые могут привести к высоким затратам.

## Преимущества проекта

- **Глубокий анализ кода** - специализированные парсеры для разных языков
- **Гибкие настройки** - контроль над включением/исключением файлов
- **Семантический поиск** - использование векторных вложений
- **Модульная архитектура** - четкое разделение компонентов
- **Локальный анализ** - минимизация данных, отправляемых в LLM
- **Инкрементальные обновления** - обновление только измененных файлов
- **Универсальная совместимость** - работает с различными API LLM

## Ограничения и диагностика

### Известные ограничения
- Зависит от способности LLM правильно следовать формату
- Большие проекты могут требовать значительных ресурсов
- Увеличенный размер промпта из-за включения результатов функций

### Советы по диагностике
Если LLM неправильно форматирует вызовы функций:
1. Проверьте системный промпт на наличие понятных инструкций
2. Используйте более низкую температуру (0-0.2)
3. Добавьте примеры использования функций

## Вклад в проект

Мы приветствуем вклад в проект! Если у вас есть предложения по улучшению или вы нашли ошибку:

1. Создайте issue
2. Отправьте pull request с предлагаемыми изменениями

## Лицензия

Проект распространяется под лицензией MIT